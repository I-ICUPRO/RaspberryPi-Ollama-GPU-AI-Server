### Как я настроил мощный локальный ИИ с UmbrelOS и Ollama (просто и понятно для всех)

#### Моя идея
Я хотел мощный ИИ у себя дома, но UmbrelOS не поддерживает видеокарты (GPU), а мне нужна была их мощность для Ollama. И я придумал: пусть UmbrelOS с OpenWebUI работает на слабом устройстве (например, Raspberry Pi или мини-ПК), а Ollama с GPU — на мощном компьютере. Они общаются через сеть, и всё летает! Вот как это сделать.

---

#### Что тебе понадобится
1. **Мощный компьютер** (ПК с видеокартой Nvidia или AMD) — тут будет Ollama.
2. **Второе устройство** (Raspberry Pi, мини-ПК или старый комп без GPU) — тут будет UmbrelOS с OpenWebUI.
3. **Одна сеть** — оба устройства должны быть подключены к одному роутеру (лучше по кабелю, но Wi-Fi тоже сойдёт).

---

#### Шаг 1: Настрой мощный ПК с Ollama
1. **Поставь систему**:  
   - Установи Ubuntu Server (или другую простую ОС, типа Debian). Скачай с сайта, запиши на флешку и установи.  
   - Не ставь ничего лишнего — только минимум, чтобы комп включался.
2. **Добавь поддержку видеокарты**:  
   - Если Nvidia: вбей в терминале `sudo apt update && sudo apt install nvidia-driver nvidia-cuda-toolkit`.  
   - Если AMD: ищи ROCm на сайте Ollama и ставь по их инструкции (зависит от карты).  
   - Проверь: для Nvidia вбей `nvidia-smi` — увидишь свою карту.
3. **Установи Ollama**:  
   - В терминале: `curl -fsSL https://ollama.com/install.sh | sh`.  
   - Запусти: `ollama serve`.  
   - Скачай модель, например: `ollama pull llama3`.
4. **Узнай IP компьютера**:  
   - Вбей `ip addr` и найди что-то вроде `192.168.1.100` (зависит от твоей сети). Запомни это.
5. **Проверь**:  
   - С другого устройства вбей в терминале `curl http://192.168.1.100:11434/api/version`. Если ответ пришёл — всё работает.

---

#### Шаг 2: Настрой второе устройство с UmbrelOS
1. **Выбери устройство**:  
   - Raspberry Pi (любой, даже 4 или 5), мини-ПК (типа Intel NUC) или старый ноут без видеокарты — главное, чтобы тянул систему.  
   - Мне нравится Raspberry Pi 5, но подойдёт что угодно с 2-4 ГБ памяти.
2. **Поставь UmbrelOS**:  
   - Скачай образ с getumbrel.com.  
   - Запиши на SD-карту (для Pi) или флешку (для ПК) через программу типа Balena Etcher.  
   - Вставь, включи устройство, подожди минут 5-10.
3. **Зайди в Umbrel**:  
   - Открой браузер, впиши `umbrel.local` или IP устройства (например, `192.168.1.101`).  
   - Настрой по подсказкам (логин, пароль).
4. **Установи OpenWebUI**:  
   - В магазине приложений Umbrel найди OpenWebUI и нажми "Установить".
5. **Соедини с Ollama**:  
   - Зайди в настройки OpenWebUI.  
   - Найди поле для API, впиши `http://192.168.1.100:11434` (IP твоего ПК из шага 1).  
   - Сохрани и перезапусти OpenWebUI.
6. **Проверь**:  
   - Открой OpenWebUI в браузере, напиши что-нибудь (например, "Привет, как дела?").  
   - Если отвечает — ура, всё получилось!

---

#### Как это работает
- Мощный ПК с видеокартой считает все модели в Ollama (это как мозг).  
- Второе устройство с UmbrelOS показывает тебе чат через OpenWebUI (это как лицо).  
- Они общаются через сеть: OpenWebUI шлёт запросы на IP твоего ПК, а Ollama отвечает.

---

#### Полезные советы
- **Сеть**: Если что-то не работает, проверь, что оба устройства видят друг друга. Вбей `ping 192.168.1.100` с Umbrel-устройства.  
- **Фаервол**: Если запросы не доходят, на ПК вбей `sudo ufw allow 11434` — это откроет порт.  
- **Автозапуск**: Чтобы Ollama сама включалась на ПК, погугли "systemd service Ollama" — там пара команд.  
- **Модели**: Качай разные модели в Ollama (llama3, mistral), чтобы выбрать, что тебе нравится.

---

#### Почему это круто
- UmbrelOS не умеет использовать видеокарты, но я обошёл это, разделив задачу на два устройства.  
- Теперь у меня супермощный ИИ дома, и всё локально — никаких облаков!  
- Ты тоже можешь это сделать, даже если не шаришь в коде, — просто следуй шагам.